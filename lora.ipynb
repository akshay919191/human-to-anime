{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40554a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "import math\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59801d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id , torch_dtype=torch.float16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoraLAYER(nn.Module):\n",
    "  def __init__(self , original , rank = 32 , alpha = 32):\n",
    "    super().__init__()  \n",
    "    self.original = original\n",
    "    in_feat = original.in_features\n",
    "    out_feat = original.out_features\n",
    "    \n",
    "    self.lora_A = torch.nn.Parameter(torch.randn(in_feat, rank))\n",
    "\n",
    "    self.lora_B = torch.nn.Parameter(torch.zeros(rank, out_feat))\n",
    "    self.scaling = alpha / rank\n",
    "  def forward(self , x):\n",
    "    return self.original(x) + (torch.matmul(torch.matmul(x, self.lora_A), self.lora_B)) * self.scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet.requires_grad_(False)\n",
    "pipe.unet.to(device=\"cuda\", dtype=torch.float16)\n",
    "for name , module in pipe.unet.named_modules():\n",
    "  if \"attn\" in name and isinstance(module , nn.Linear):\n",
    "    parent_name = \".\".join(name.split(\".\")[:-1])\n",
    "    layer_name = name.split(\".\")[-1]\n",
    "    parent = pipe.unet.get_submodule(parent_name)\n",
    "\n",
    "    new = LoraLAYER(module, rank=64, alpha=64)\n",
    "    new.to(device = \"cuda\" , dtype=torch.float16)\n",
    "    setattr(parent, layer_name, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4444ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DatasetA(Dataset):\n",
    "  def __init__(self , img_Dir , cap_Dir , tokenizer , size = 512):\n",
    "    super().__init__()\n",
    "    self.img_Dir = img_Dir\n",
    "    self.cap_Dir = cap_Dir\n",
    "    self.tokenizer = tokenizer\n",
    "    self.images = [f for f in os.listdir(img_Dir) if f.endswith(('.png', '.jpg'))]\n",
    "    self.transform = transforms.Compose([\n",
    "        transforms.Resize((size, size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5] , [0.5])\n",
    "    ])\n",
    "  def __len__(self): return len(self.images)\n",
    "  def __getitem__(self , idx):\n",
    "    image_name = self.images[idx]\n",
    "    image_path = os.path.join(self.img_Dir , self.images[idx])\n",
    "    image = self.transform(Image.open(image_path).convert(\"RGB\"))\n",
    "    \n",
    "  \n",
    "    txt_filename = os.path.splitext(image_name)[0] + \".txt\"\n",
    "    txt_path = os.path.join(self.cap_Dir, txt_filename)\n",
    "    with open(txt_path, 'r') as f:\n",
    "      caption = f.read().strip()\n",
    "\n",
    "    tokens = self.tokenizer(caption, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids[0]\n",
    "    return image, tokens\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce909181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainDATA = DatasetA(img_Dir =  \"/content/data/anime_images\", cap_Dir =  \"/content/data/info\" , tokenizer = pipe.tokenizer)\n",
    "trainLOADER = DataLoader(trainDATA , batch_size = 4 , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211cac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pipe.unet.to(dtype=torch.float32)\n",
    "\n",
    "param_main = [p for p in pipe.unet.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(param_main, lr=5e-6)\n",
    "\n",
    "pipe.vae.to(dtype=torch.float32)\n",
    "pipe.text_encoder.to(dtype=torch.float32)\n",
    "pipe.unet.to(dtype=torch.float32)\n",
    "pipe.unet.train() \n",
    "for param in pipe.unet.parameters():\n",
    "    param.data = param.data.to(torch.float32)\n",
    "    if param.grad is not None:\n",
    "        param.grad.data = param.grad.data.to(torch.float32)\n",
    "\n",
    "\n",
    "param_main = [p for p in pipe.unet.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(param_main, lr=1e-5)\n",
    "\n",
    "for step, (pixel, index) in enumerate(trainLOADER):\n",
    "    # Inputs to GPU + Float32\n",
    "    pixel = pixel.to(\"cuda\", dtype=torch.float32)\n",
    "    index = index.to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Latents must be Float32\n",
    "        latents = pipe.vae.encode(pixel).latent_dist.sample() * 0.18215\n",
    "        # Embeddings must be Float32\n",
    "        encoder_hidden_states = pipe.text_encoder(index)[0]\n",
    "\n",
    "    noise = torch.randn_like(latents).to(\"cuda\", dtype=torch.float32)\n",
    "    timestep = torch.randint(0, 1000, (latents.shape[0],), device=\"cuda\").long()\n",
    "    noisy_latents = pipe.scheduler.add_noise(latents, noise, timestep)\n",
    "\n",
    "    # UNet Pass\n",
    "    model_pred = pipe.unet(\n",
    "        noisy_latents, \n",
    "        timestep, \n",
    "        encoder_hidden_states=encoder_hidden_states\n",
    "    ).sample\n",
    "\n",
    "    loss = F.mse_loss(model_pred, noise, reduction=\"mean\")\n",
    "    \n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(param_main, 1.0)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print(f\"Step {step} | Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
